{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import  numpy.random as random\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def push_batch(self, batch):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            append_len = min(self.capacity - len(self.buffer), len(batch))\n",
    "            self.buffer.extend([None] * append_len)\n",
    "\n",
    "        if self.position + len(batch) < self.capacity:\n",
    "            self.buffer[self.position : self.position + len(batch)] = batch\n",
    "            self.position += len(batch)\n",
    "        else:\n",
    "            self.buffer[self.position : len(self.buffer)] = batch[:len(self.buffer) - self.position]\n",
    "            self.buffer[:len(batch) - len(self.buffer) + self.position] = batch[len(self.buffer) - self.position:]\n",
    "            self.position = len(batch) - len(self.buffer) + self.position\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            batch_size = len(self.buffer)\n",
    "        batch = random.sample(self.buffer, int(batch_size))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def sample_all_batch(self, batch_size):\n",
    "        idxes = np.random.randint(0, len(self.buffer), batch_size)\n",
    "        batch = list(itemgetter(*idxes)(self.buffer))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def return_all(self):\n",
    "        return self.buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV:\n",
    "    def __init__(self,A,B,Q,R,target_state=np.ones(3)):\n",
    "        self.A=A\n",
    "        self.B=B\n",
    "        self.Q=Q\n",
    "        self.R=R\n",
    "        self.target_state=target_state\n",
    "        self.current_action=None\n",
    "        self.current_state=None\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state=np.ones(len(self.A))\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self,action):\n",
    "        mean = self.A@np.array([self.current_state]).T + self.B@action\n",
    "        print(mean)\n",
    "        next_state=np.random.multivariate_normal(mean.T[0],np.eye(len(mean)))\n",
    "        part_1=np.array([next_state])@self.Q@np.array([next_state]).T\n",
    "        part_2=action.T@self.R@action\n",
    "        \n",
    "        self.current_action=action\n",
    "        \n",
    "        # if next_state==self.target_state:\n",
    "        #     return part_1+part_2,next_state,True\n",
    "        return part_1+part_2,next_state,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Estimate(A_hat,B_hat,Q_hat,R_hat,D_real):\n",
    "    if len(D_real)==0:\n",
    "        return A_hat,B_hat,Q_hat,R_hat\n",
    "    dim_state=D_real[0][0].shape\n",
    "    dim_action=D_real[0][1].shape\n",
    "    X=np.zeros(shape=(dim_state+dim_action,len(D_real)))\n",
    "    Y=np.zeros(shape=(dim_state,len(D_real)))\n",
    "    for i in range(len(D_real)):\n",
    "        Y[:,i]=D_real[i][2]\n",
    "        X[:,i]=np.concatenate(D_real[i][0],D_real[i][1])\n",
    "    A=X.T\n",
    "    b=Y.T\n",
    "    total_hat=lstsq(A,b) # need to split\n",
    "    return total_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_state(env_pool):\n",
    "    space=[x[0] for x in env_pool] \n",
    "    return np.random.choice(space)\n",
    "\n",
    "def gradient_with_model(A,B):\n",
    "    \n",
    "    grad=4\n",
    "    return grad \n",
    "\n",
    "def gradient_with_exp(D_fake):\n",
    "    \n",
    "    grad=4\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_traj(S_t,horiz_len,A_hat,B_hat,Q_hat,R_hat,K_t):\n",
    "    i=0\n",
    "    holder=[]\n",
    "    while i<horiz_len:\n",
    "        prev=S_t\n",
    "        u_T=K_t*S_t\n",
    "        S_t=A_hat*S_t+B_hat*u_T+np.random.normal(0,1)\n",
    "        R_t=0.5*[S_t]@Q_hat@[S_t].T + 0.5*[u_T]@R_hat@[u_T].T\n",
    "        done_t=False\n",
    "        if S_t==np.zeros_like(S_t):\n",
    "            done_t=True\n",
    "        holder.append((prev,u_T,R_t,S_t,done_t))\n",
    "        i+=1\n",
    "    return holder\n",
    "\n",
    "def get_from_env(K_t,env,len_traj):\n",
    "    \n",
    "    i=0\n",
    "    Is_done=False\n",
    "    holder=[]\n",
    "    while i<len_traj and Is_done!=True:\n",
    "        u_T=K_t@np.array([env.current_state]).T\n",
    "        R_t,S_t,Is_done=env.step(u_T)\n",
    "        holder.append((env.current_state,u_T,R_t,S_t,Is_done))\n",
    "        env.current_state=S_t\n",
    "        if Is_done:\n",
    "            break\n",
    "        i+=1  \n",
    "    return holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ->>3*3\n",
    "# B ->>3*3\n",
    "# C->eye(3)\n",
    "# K ->>3*3\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# True parameters of the env\n",
    "\n",
    "A=np.diag([1,-2,3])\n",
    "B=np.diag([1,2,3])\n",
    "C=np.eye(3)\n",
    "Q=np.diag([1,2,3])\n",
    "R=np.diag([5,1,3])\n",
    "\n",
    "\n",
    "\n",
    "A_hat=np.random.rand(3,3)   # Initial theta\n",
    "B_hat=np.random.rand(3,3)   # Initial theta\n",
    "Q_hat=np.diag(np.ones(3))   # Initial theta\n",
    "R_hat=np.diag(np.ones(3))   # Initial theta\n",
    "\n",
    "K=np.random.rand(3,3)   # Initial phi\n",
    "K_t=K\n",
    "\n",
    "D_real = ReplayMemory(10000)   # Real data\n",
    "D_fake = ReplayMemory(10000)  # Fake data\n",
    "\n",
    "\n",
    "env=ENV(A,B,Q,R)\n",
    "env.reset() # Reset\n",
    "################################################################\n",
    "\n",
    "num_of_epcoh=20\n",
    "N=10\n",
    "E=10\n",
    "M=10\n",
    "G=10\n",
    "horiz_len=10\n",
    "num_of_rollouts=10\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.62678724]\n",
      " [2.08233421]\n",
      " [5.7046462 ]]\n",
      "[[16.95595767]\n",
      " [18.18348684]\n",
      " [31.51907013]]\n",
      "[[ 74.08588398]\n",
      " [ 54.05371311]\n",
      " [147.96640313]]\n",
      "[[327.72185404]\n",
      " [292.28803595]\n",
      " [641.48750381]]\n",
      "[[1462.76801088]\n",
      " [1208.86506616]\n",
      " [2869.38324889]]\n",
      "[[ 6461.51055323]\n",
      " [ 5516.44036869]\n",
      " [12686.31163105]]\n",
      "[[28705.51120661]\n",
      " [24192.04879594]\n",
      " [56396.40728274]]\n",
      "[[127276.06377619]\n",
      " [107859.94770423]\n",
      " [250062.48752869]]\n",
      "[[ 564874.59052313]\n",
      " [ 477623.01495941]\n",
      " [1109953.56646449]]\n",
      "[[2506191.18041402]\n",
      " [2121125.95896799]\n",
      " [4924556.36584909]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(E):\n\u001b[1;32m      4\u001b[0m     S_t\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;28mlen\u001b[39m(A_hat)) \u001b[38;5;66;03m# Update D_real\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     sup\u001b[38;5;241m=\u001b[39mget_from_env(K_t,env,\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      6\u001b[0m     D_real\u001b[38;5;241m.\u001b[39mpush(sup)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n",
      "Cell \u001b[0;32mIn [79], line 23\u001b[0m, in \u001b[0;36mget_from_env\u001b[0;34m(K_t, env, len_traj)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i\u001b[38;5;241m<\u001b[39mlen_traj \u001b[38;5;129;01mand\u001b[39;00m Is_done\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     u_T\u001b[38;5;241m=\u001b[39mK_t\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([env\u001b[38;5;241m.\u001b[39mcurrent_state])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 23\u001b[0m     R_t,S_t,Is_done\u001b[38;5;241m=\u001b[39m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu_T\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     holder\u001b[38;5;241m.\u001b[39mappend((env\u001b[38;5;241m.\u001b[39mcurrent_state,u_T,R_t,S_t,Is_done))\n\u001b[1;32m     25\u001b[0m     env\u001b[38;5;241m.\u001b[39mcurrent_state\u001b[38;5;241m=\u001b[39mS_t\n",
      "Cell \u001b[0;32mIn [83], line 18\u001b[0m, in \u001b[0;36mENV.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     16\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_state])\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;129m@action\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean)\n\u001b[0;32m---> 18\u001b[0m next_state\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m part_1\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([next_state])\u001b[38;5;129m@self\u001b[39m\u001b[38;5;241m.\u001b[39mQ\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([next_state])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     20\u001b[0m part_2\u001b[38;5;241m=\u001b[39maction\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@self\u001b[39m\u001b[38;5;241m.\u001b[39mR\u001b[38;5;129m@action\u001b[39m\n",
      "File \u001b[0;32mmtrand.pyx:4162\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in range(num_of_epcoh):\n",
    "    A_hat,B_hat,Q_hat,R_hat=New_Estimate(A_hat,B_hat,Q_hat,R_hat,D_real) # Regression \n",
    "    for e in range(E):\n",
    "        S_t=np.random.rand(len(A_hat)) # Update D_real\n",
    "        sup=get_from_env(K_t,env,20)\n",
    "        D_real.push(sup)\n",
    "        for m in range(M):\n",
    "            S_t=Sample_state(D_real)    # Random sampling\n",
    "            D_fake.push(get_fake_traj(S_t,horiz_len,A_hat,B_hat,K_t))\n",
    "            # Update D_fake with horiz_len\n",
    "        for g in range(G):\n",
    "            K_t+=gradient_with_model(A_hat,B_hat)    # Known parameter\n",
    "            K_t+=gradient_with_exp(D_fake)    # unKnown parameter (From trajectories -off policy settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
