{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import  numpy.random as random\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def push_batch(self, batch):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            append_len = min(self.capacity - len(self.buffer), len(batch))\n",
    "            self.buffer.extend([None] * append_len)\n",
    "\n",
    "        if self.position + len(batch) < self.capacity:\n",
    "            self.buffer[self.position : self.position + len(batch)] = batch\n",
    "            self.position += len(batch)\n",
    "        else:\n",
    "            self.buffer[self.position : len(self.buffer)] = batch[:len(self.buffer) - self.position]\n",
    "            self.buffer[:len(batch) - len(self.buffer) + self.position] = batch[len(self.buffer) - self.position:]\n",
    "            self.position = len(batch) - len(self.buffer) + self.position\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            batch_size = len(self.buffer)\n",
    "        batch = random.sample(self.buffer, int(batch_size))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def sample_all_batch(self, batch_size):\n",
    "        idxes = np.random.randint(0, len(self.buffer), batch_size)\n",
    "        batch = list(itemgetter(*idxes)(self.buffer))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def return_all(self):\n",
    "        return self.buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV:\n",
    "    def __init__(self,A,B,Q,R,target_state=np.ones(3)):\n",
    "        self.A=A\n",
    "        self.B=B\n",
    "        self.Q=Q\n",
    "        self.R=R\n",
    "        self.target_state=target_state\n",
    "        self.current_action=None\n",
    "        self.current_state=None\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state=np.ones(shape=(len(self.A),1)).T\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self,action):\n",
    "        mean = self.A@self.current_state.T + self.B@action\n",
    "        next_state=np.random.multivariate_normal(mean.T[0],np.eye(len(mean)))\n",
    "        part_1=np.array([next_state])@self.Q@np.array([next_state]).T\n",
    "        part_2=action*self.R*action\n",
    "        \n",
    "        self.current_state=next_state\n",
    "        self.current_action=action\n",
    "        \n",
    "        if next_state==self.target_state:\n",
    "            return part_1+part_2,next_state,True\n",
    "        return part_1+part_2,next_state,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Estimate(A_hat,B_hat,Q_hat,R_hat,D_real):\n",
    "    if len(D_real)==0:\n",
    "        return A_hat,B_hat,Q_hat,R_hat\n",
    "    dim_state=D_real[0][0].shape\n",
    "    dim_action=D_real[0][1].shape\n",
    "    X=np.zeros(shape=(dim_state+dim_action,len(D_real)))\n",
    "    Y=np.zeros(shape=(dim_state,len(D_real)))\n",
    "    for i in range(len(D_real)):\n",
    "        Y[:,i]=D_real[i][2]\n",
    "        X[:,i]=np.concatenate(D_real[i][0],D_real[i][1])\n",
    "    A=X.T\n",
    "    b=Y.T\n",
    "    total_hat=lstsq(A,b) # need to split\n",
    "    return total_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_state(env_pool):\n",
    "    space=[x[0] for x in env_pool] \n",
    "    return np.random.choice(space)\n",
    "\n",
    "def gradient_with_model(A,B):\n",
    "    \n",
    "    grad=4\n",
    "    return grad \n",
    "\n",
    "def gradient_with_exp(D_fake):\n",
    "    \n",
    "    grad=4\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fake_traj(S_t,horiz_len,A_hat,B_hat,Q_hat,R_hat,K_t):\n",
    "    i=0\n",
    "    holder=[]\n",
    "    while i<horiz_len:\n",
    "        prev=S_t\n",
    "        u_T=K_t*S_t\n",
    "        S_t=A_hat*S_t+B_hat*u_T+np.random.normal(0,1)\n",
    "        R_t=0.5*[S_t]@Q_hat@[S_t].T + 0.5*[u_T]@R_hat@[u_T].T\n",
    "        done_t=False\n",
    "        if S_t==np.zeros_like(S_t):\n",
    "            done_t=True\n",
    "        holder.append((prev,u_T,R_t,S_t,done_t))\n",
    "        i+=1\n",
    "    return holder\n",
    "\n",
    "def get_from_env(S_t,K_t,env,len_traj):\n",
    "    \n",
    "    i=0\n",
    "    Is_done=False\n",
    "    holder=[]\n",
    "    while i<len_traj and Is_done!=True:\n",
    "        prev=S_t\n",
    "        u_T=K_t*S_t\n",
    "        R_t,S_t,Is_done=env.step(u_T)\n",
    "        holder.append((prev,u_T,R_t,S_t,Is_done))\n",
    "        if Is_done:\n",
    "            break\n",
    "        i+=1  \n",
    "    return holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ->>3*3\n",
    "# B ->>3*3\n",
    "# C->eye(3)\n",
    "# K ->>3*3\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# True parameters of the env\n",
    "\n",
    "A=np.diag([1,-2,3])\n",
    "B=np.diag([1,2,3])\n",
    "C=np.eye(3)\n",
    "Q=np.diag([1,2,3])\n",
    "R=np.diag([5,1,3])\n",
    "\n",
    "\n",
    "\n",
    "A_hat=np.random.rand(3,3)   # Initial theta\n",
    "B_hat=np.random.rand(3,3)   # Initial theta\n",
    "Q_hat=np.diag(np.ones(3))   # Initial theta\n",
    "R_hat=np.diag(np.ones(3))   # Initial theta\n",
    "\n",
    "K=np.random.rand(3,3)   # Initial phi\n",
    "K_t=K\n",
    "\n",
    "D_real = ReplayMemory()   # Real data\n",
    "D_fake = ReplayMemory()  # Fake data\n",
    "\n",
    "\n",
    "env=ENV(A,B,Q,R)\n",
    "\n",
    "################################################################\n",
    "\n",
    "num_of_epcoh=20\n",
    "N=10\n",
    "E=10\n",
    "M=10\n",
    "G=10\n",
    "horiz_len=10\n",
    "num_of_rollouts=10\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(num_of_epcoh):\n",
    "    A_hat,B_hat,Q_hat,R_hat=New_Estimate(A_hat,B_hat,Q_hat,R_hat,D_real) # Regression \n",
    "    for e in range(E):\n",
    "        S_t=np.random.rand(len(A_hat)) # Update D_real\n",
    "        D_real.push(get_from_env(S_t,K_t,20))\n",
    "        for m in range(M):\n",
    "            S_t=Sample_state(D_real)    # Random sampling\n",
    "            D_fake.push(get_fake_traj(S_t,horiz_len,A_hat,B_hat,K_t))\n",
    "            # Update D_fake with horiz_len\n",
    "        for g in range(G):\n",
    "            K_t+=gradient_with_model(A_hat,B_hat)    # Known parameter\n",
    "            K_t+=gradient_with_exp(D_fake)    # unKnown parameter (From trajectories -off policy settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
