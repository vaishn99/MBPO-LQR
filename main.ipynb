{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "import  numpy.random as random\n",
    "from operator import itemgetter\n",
    "from control import lqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "\n",
    "num_of_epcoh=20\n",
    "N=10\n",
    "E=10\n",
    "M=10\n",
    "G=10\n",
    "horiz_len=10\n",
    "num_of_rollouts=10\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def push_batch(self, batch):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            append_len = min(self.capacity - len(self.buffer), len(batch))\n",
    "            self.buffer.extend([None] * append_len)\n",
    "\n",
    "        if self.position + len(batch) < self.capacity:\n",
    "            self.buffer[self.position : self.position + len(batch)] = batch\n",
    "            self.position += len(batch)\n",
    "        else:\n",
    "            self.buffer[self.position : len(self.buffer)] = batch[:len(self.buffer) - self.position]\n",
    "            self.buffer[:len(batch) - len(self.buffer) + self.position] = batch[len(self.buffer) - self.position:]\n",
    "            self.position = len(batch) - len(self.buffer) + self.position\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if batch_size > len(self.buffer):\n",
    "            batch_size = len(self.buffer)\n",
    "        batch = random.sample(self.buffer, int(batch_size))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def sample_all_batch(self, batch_size):\n",
    "        idxes = np.random.randint(0, len(self.buffer), batch_size)\n",
    "        batch = list(itemgetter(*idxes)(self.buffer))\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "\n",
    "    def return_all(self):\n",
    "        return self.buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV:\n",
    "    def __init__(self,A,B,Q,R,target_state=np.ones(3)):\n",
    "        self.A=A\n",
    "        self.B=B\n",
    "        self.Q=Q\n",
    "        self.R=R\n",
    "        self.target_state=target_state\n",
    "        self.current_action=None\n",
    "        self.current_state=None\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state=np.array([0.4,-0.6,0.2])\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self,action):\n",
    "        mean = self.A@np.array([self.current_state]).T + self.B@action\n",
    "        next_state=np.random.multivariate_normal(mean.T[0],np.eye(len(mean)))\n",
    "        part_1=np.array([next_state])@self.Q@np.array([next_state]).T\n",
    "        part_2=action.T@self.R@action\n",
    "        \n",
    "        self.current_action=action\n",
    "        \n",
    "        # if next_state==self.target_state:\n",
    "        #     return part_1+part_2,next_state,True\n",
    "        \n",
    "        return part_1+part_2,next_state,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Estimate(D_real):\n",
    "    \n",
    "    # Need to figure out the problem.\n",
    "    \n",
    "    if len(D_real)==0:\n",
    "        return -1\n",
    "    dim_state=D_real.buffer[0][0].shape[0]\n",
    "    dim_action=D_real.buffer[0][1].shape[0]\n",
    "    \n",
    "    A_T=np.zeros(shape=(dim_state+dim_action,len(D_real)))\n",
    "    b_T=np.zeros(shape=(dim_state,len(D_real)))\n",
    "    for i in range(len(D_real)):\n",
    "        b_T[:,i]=D_real.buffer[i][3]\n",
    "        A_T[:,i]=np.concatenate((D_real.buffer[i][0],D_real.buffer[i][1].T[0]))\n",
    "    A=A_T.T\n",
    "    b=b_T.T\n",
    "    total_hat=lstsq(A,b)[0] # need to split\n",
    "    A_hat=total_hat[:dim_state]\n",
    "    B_hat=total_hat[dim_state:]\n",
    "    \n",
    "    A=np.zeros(shape=(len(D_real),dim_state+dim_action))\n",
    "    b=np.zeros(shape=(len(D_real),1))\n",
    "    for i in range(len(D_real.buffer)):\n",
    "        A[i,:]=np.concatenate((D_real.buffer[i][0],D_real.buffer[i][1].T[0]))\n",
    "        b[i,:]=D_real.buffer[i][2]\n",
    "    total_hat=lstsq(A,b)[0]\n",
    "    total_hat=total_hat.T[0]\n",
    "    Q_hat=total_hat[:dim_state]\n",
    "    R_hat=total_hat[dim_state:]\n",
    "    Q_hat=np.diag(Q_hat)\n",
    "    R_hat=np.diag(R_hat)\n",
    "    model= [A_hat,B_hat,Q_hat,R_hat]  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_state(D_real):\n",
    "    ind=np.random.randint(low=0,high=D_real.position) \n",
    "    return D_real.buffer[ind][0]\n",
    "\n",
    "def gradient_with_model(A,B):\n",
    "    grad=4\n",
    "    return grad \n",
    "\n",
    "def gradient_with_exp(D_fake):\n",
    "    grad=4\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_D_fake(S_t,model,K_t,D_fake):\n",
    "    \n",
    "    A_hat,B_hat,Q_hat,R_hat=model[0],model[1],model[2],model[3]\n",
    "    \n",
    "    i=0\n",
    "    holder=[]\n",
    "    Is_done=False\n",
    "    \n",
    "    while i<horiz_len and Is_done!=True:\n",
    "        prev=S_t\n",
    "        u_T=K_t@np.array([S_t]).T\n",
    "        S_t=A_hat@np.array([S_t]).T+B_hat@u_T\n",
    "        \n",
    "        next_state=np.random.multivariate_normal(S_t.T[0],np.eye(len(S_t)))\n",
    "        \n",
    "        part_1=np.array([next_state])@Q_hat@np.array([next_state]).T\n",
    "        part_2=u_T.T@R_hat@u_T\n",
    "        S_t=next_state\n",
    "        \n",
    "        Is_done=False\n",
    "        \n",
    "        D_fake.push(prev,u_T,part_1[0][0]+part_2[0][0],next_state,Is_done)\n",
    "        i+=1\n",
    "    \n",
    "    return \n",
    "\n",
    "def update_D_real(K_t,env,D_real):\n",
    "    \n",
    "    i=0\n",
    "    Is_done=False\n",
    "    while i<horiz_len and Is_done!=True:\n",
    "        u_T=K_t@np.array([env.current_state]).T\n",
    "        R_t,S_t,Is_done=env.step(u_T)\n",
    "        D_real.push(env.current_state,u_T,R_t[0][0],S_t,Is_done)\n",
    "        env.current_state=S_t\n",
    "        if Is_done:\n",
    "            break\n",
    "        i+=1  \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ->>3*3\n",
    "# B ->>3*3\n",
    "# C->eye(3)\n",
    "# K ->>3*3\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# True parameters of the env\n",
    "\n",
    "A=np.diag([-0.1,-0.2,0.3])\n",
    "B=np.diag([.1,0,0])\n",
    "C=np.eye(3)\n",
    "Q=np.diag([.4,0.2,0.1])\n",
    "R=np.diag([.5,0.1,.1])\n",
    "\n",
    "\n",
    "\n",
    "A_hat=np.random.rand(3,3)   # Initial theta\n",
    "B_hat=np.random.rand(3,3)   # Initial theta\n",
    "Q_hat=np.diag(np.ones(3))   # Initial theta\n",
    "R_hat=np.diag(np.ones(3))   # Initial theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "K=np.random.rand(3,3)   # Initial phi\n",
    "K_t=K\n",
    "\n",
    "D_real = ReplayMemory(10000)   # Real data\n",
    "D_fake = ReplayMemory(10000)  # Fake data\n",
    "\n",
    "\n",
    "env=ENV(A,B,Q,R)\n",
    "env.reset() # Reset\n",
    "################################################################\n",
    "\n",
    "num_of_epcoh=20\n",
    "N=10\n",
    "E=10\n",
    "M=10\n",
    "G=10\n",
    "horiz_len=10\n",
    "num_of_rollouts=10\n",
    "\n",
    "################################################################\n",
    "\n",
    "# model=[A_hat,B_hat,Q_hat,R_hat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage0\n",
      "\n",
      "0.2506575250131854\n",
      "\n",
      "\n",
      "0.17710668954003939\n",
      "\n",
      "\n",
      "0.6974885983553187\n",
      "\n",
      "\n",
      "0.6767892294685873\n",
      "\n",
      "\n",
      "Stage9\n",
      "\n",
      "13326253049831.145\n",
      "\n",
      "\n",
      "54135215294804.21\n",
      "\n",
      "\n",
      "26683947467179.777\n",
      "\n",
      "\n",
      "108398154803861.48\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimation check \n",
    "\n",
    "for i in range(10):\n",
    "    for e in range(10):\n",
    "        update_D_real(K_t,env,D_real)   # Update D_real\n",
    "    model=New_Estimate(D_real)\n",
    "    if i==0 or i==9:\n",
    "        print(\"Stage\"+str(i)+\"\\n\")\n",
    "        Test_Fun(model,A,B,Q,R)\n",
    "\n",
    "# for e in range(10):\n",
    "#     update_D_real(K_t,env,D_real)   # Update D_real\n",
    "# model=New_Estimate(D_real)\n",
    "# print(\"Stage 2\\n\")\n",
    "# Test_Fun(model,A,B,Q,R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_Fun(model,A,B,Q,R):\n",
    "    print(np.linalg.norm(model[0]-A))\n",
    "    print(\"\\n\")\n",
    "    print(np.linalg.norm(model[1]-B))\n",
    "    print(\"\\n\")\n",
    "    print(np.linalg.norm(model[2]-Q))\n",
    "    print(\"\\n\")\n",
    "    print(np.linalg.norm(model[3]-R))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue occured: diverging Entries in Matrix,state vector\n",
    "# Solution : Find best set of param for the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [106], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(M):\n\u001b[1;32m      9\u001b[0m     S_t\u001b[38;5;241m=\u001b[39mSample_state(D_real)    \u001b[38;5;66;03m# Random sampling\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     update_D_fake(S_t,model,K_t,D_fake) \u001b[38;5;66;03m# update_D_fake\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Working till here\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(G):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# K_t,gradient_with_model(A_hat,B_hat)    # Known parameter\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [74], line 14\u001b[0m, in \u001b[0;36mupdate_D_fake\u001b[0;34m(S_t, model, K_t, D_fake)\u001b[0m\n\u001b[1;32m     11\u001b[0m u_T\u001b[38;5;241m=\u001b[39mK_t\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([S_t])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     12\u001b[0m S_t\u001b[38;5;241m=\u001b[39mA_hat\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([S_t])\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m+\u001b[39mB_hat\u001b[38;5;129m@u_T\u001b[39m\n\u001b[0;32m---> 14\u001b[0m next_state\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mS_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m part_1\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([next_state])\u001b[38;5;129m@Q_hat\u001b[39m\u001b[38;5;129m@np\u001b[39m\u001b[38;5;241m.\u001b[39marray([next_state])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     17\u001b[0m part_2\u001b[38;5;241m=\u001b[39mu_T\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@R_hat\u001b[39m\u001b[38;5;129m@u_T\u001b[39m\n",
      "File \u001b[0;32mmtrand.pyx:4162\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in range(num_of_epcoh):\n",
    "    model=New_Estimate(D_real) # Regression\n",
    "    if model==-1:\n",
    "        model=[A_hat,B_hat,Q_hat,R_hat]  # start \n",
    "    for e in range(E):\n",
    "        S_t=np.random.rand(len(A_hat)) # Update D_real\n",
    "        update_D_real(K_t,env,D_real)\n",
    "        for m in range(M):\n",
    "            S_t=Sample_state(D_real)    # Random sampling\n",
    "            update_D_fake(S_t,model,K_t,D_fake) # update_D_fake\n",
    "            # Working till here\n",
    "        for g in range(G):\n",
    "            # K_t,gradient_with_model(A_hat,B_hat)    # Known parameter\n",
    "            K_t+=gradient_with_exp(D_fake)    # unKnown parameter (From trajectories -off policy settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_T,_,_=lqr(A_hat,B_hat,Q_hat,R_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.802737753489131\n",
      "8.077587538668679\n",
      "5.747939206884088\n",
      "7.959241349739015\n",
      "14.829621617865602\n",
      "142.49346523124066\n",
      "806.378276930247\n",
      "186.2011197926539\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "The associated Hamiltonian pencil has eigenvalues too close to the imaginary axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [108], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     update_D_real(K_t,env,D_real)   \u001b[38;5;66;03m# Update D_real\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m=\u001b[39mNew_Estimate(D_real)\n\u001b[0;32m----> 8\u001b[0m K_t,_,_\u001b[38;5;241m=\u001b[39mlqr(model[\u001b[38;5;241m0\u001b[39m],model[\u001b[38;5;241m1\u001b[39m],model[\u001b[38;5;241m2\u001b[39m],model[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(K_T\u001b[38;5;241m-\u001b[39mK_t))    \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# for m in range(M):\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#     S_t=Sample_state(D_real)    # Random sampling\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#     update_D_fake(S_t,model,K_t,D_fake) # update_D_fake\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# K_t,gradient_with_model(A_hat,B_hat)    # Known parameter\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# K_t+=gradient_with_exp(D_fake)    # unKnown parameter (From trajectories -off policy settings)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/control/statefbk.py:456\u001b[0m, in \u001b[0;36mlqr\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized keywords: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(kwargs))\n\u001b[1;32m    455\u001b[0m \u001b[39m# Compute the result (dimension and symmetry checking done in care())\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m X, L, G \u001b[39m=\u001b[39m care(A, B, Q, R, N, \u001b[39mNone\u001b[39;49;00m, method\u001b[39m=\u001b[39;49mmethod, S_s\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mN\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    457\u001b[0m \u001b[39mreturn\u001b[39;00m G, X, L\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/control/mateqn.py:430\u001b[0m, in \u001b[0;36mcare\u001b[0;34m(A, B, Q, R, S, E, stabilizing, method, A_s, B_s, Q_s, R_s, S_s, E_s)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stabilizing:\n\u001b[1;32m    427\u001b[0m     \u001b[39mraise\u001b[39;00m ControlArgument(\n\u001b[1;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmethod=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscipy\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not valid when stabilizing is not True\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 430\u001b[0m X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49msolve_continuous_are(A, B, Q, R)\n\u001b[1;32m    431\u001b[0m K \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msolve(R, B\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m X)\n\u001b[1;32m    432\u001b[0m E, _ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meig(A \u001b[39m-\u001b[39m B \u001b[39m@\u001b[39m K)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/linalg/_solvers.py:523\u001b[0m, in \u001b[0;36msolve_continuous_are\u001b[0;34m(a, b, q, r, e, s, balanced)\u001b[0m\n\u001b[1;32m    520\u001b[0m sym_threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax([np\u001b[39m.\u001b[39mspacing(\u001b[39m1000.\u001b[39m), \u001b[39m0.1\u001b[39m\u001b[39m*\u001b[39mn_u_sym])\n\u001b[1;32m    522\u001b[0m \u001b[39mif\u001b[39;00m norm(u_sym, \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m sym_threshold:\n\u001b[0;32m--> 523\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m'\u001b[39m\u001b[39mThe associated Hamiltonian pencil has eigenvalues \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    524\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mtoo close to the imaginary axis\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    526\u001b[0m \u001b[39mreturn\u001b[39;00m (x \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39mconj()\u001b[39m.\u001b[39mT)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: The associated Hamiltonian pencil has eigenvalues too close to the imaginary axis"
     ]
    }
   ],
   "source": [
    "for n in range(num_of_epcoh):\n",
    "    #  # Regression\n",
    "    # if model==-1:\n",
    "    #     model=[A_hat,B_hat,Q_hat,R_hat]  # start \n",
    "    for e in range(2):\n",
    "        update_D_real(K_t,env,D_real)   # Update D_real\n",
    "    model=New_Estimate(D_real)\n",
    "    K_t,_,_=lqr(model[0],model[1],model[2],model[3])\n",
    "    print(np.linalg.norm(K_T-K_t))    \n",
    "        # for m in range(M):\n",
    "        #     S_t=Sample_state(D_real)    # Random sampling\n",
    "        #     update_D_fake(S_t,model,K_t,D_fake) # update_D_fake\n",
    "        #     # Working till here\n",
    "        \n",
    "        # for g in range(G):\n",
    "            # K_t,gradient_with_model(A_hat,B_hat)    # Known parameter\n",
    "            # K_t+=gradient_with_exp(D_fake)    # unKnown parameter (From trajectories -off policy settings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
